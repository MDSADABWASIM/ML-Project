{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda0633cb87348e4e1f83d9c32f4c55bf11",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree, Random Forest and Gradient Boosting Classifier Project\n",
    "\n",
    "In this project we will code along with some data and test out 3 different tree methods:\n",
    "\n",
    "* A single decision tree\n",
    "* A random forest\n",
    "* A gradient boosted tree classifier\n",
    "    \n",
    "We will be using a college dataset to try to classify colleges as Private or Public based off these features:\n",
    "\n",
    "    Private A factor with levels No and Yes indicating private or public university\n",
    "    Apps Number of applications received\n",
    "    Accept Number of applications accepted\n",
    "    Enroll Number of new students enrolled\n",
    "    Top10perc Pct. new students from top 10% of H.S. class\n",
    "    Top25perc Pct. new students from top 25% of H.S. class\n",
    "    F.Undergrad Number of fulltime undergraduates\n",
    "    P.Undergrad Number of parttime undergraduates\n",
    "    Outstate Out-of-state tuition\n",
    "    Room.Board Room and board costs\n",
    "    Books Estimated book costs\n",
    "    Personal Estimated personal spending\n",
    "    PhD Pct. of faculty with Ph.D.â€™s\n",
    "    Terminal Pct. of faculty with terminal degree\n",
    "    S.F.Ratio Student/faculty ratio\n",
    "    perc.alumni Pct. alumni who donate\n",
    "    Expend Instructional expenditure per student\n",
    "    Grad.Rate Graduation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier,GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Trees').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('../datasets/College_Data',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "root\n |-- _c0: string (nullable = true)\n |-- Private: string (nullable = true)\n |-- Apps: integer (nullable = true)\n |-- Accept: integer (nullable = true)\n |-- Enroll: integer (nullable = true)\n |-- Top10perc: integer (nullable = true)\n |-- Top25perc: integer (nullable = true)\n |-- F.Undergrad: integer (nullable = true)\n |-- P.Undergrad: integer (nullable = true)\n |-- Outstate: integer (nullable = true)\n |-- Room.Board: integer (nullable = true)\n |-- Books: integer (nullable = true)\n |-- Personal: integer (nullable = true)\n |-- PhD: integer (nullable = true)\n |-- Terminal: integer (nullable = true)\n |-- S.F.Ratio: double (nullable = true)\n |-- perc.alumni: integer (nullable = true)\n |-- Expend: integer (nullable = true)\n |-- Grad.Rate: integer (nullable = true)\n\n"
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='Private',outputCol='PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns so that we can pass it in assembler.\n",
    "output = output.withColumnRenamed('F.Undergrad','F_Undergrad').withColumnRenamed('P.Undergrad','P_Undergrad')                             .withColumnRenamed('S.F.Ratio','S_F_Ratio').withColumnRenamed('perc.alumni','perc_alumni')                                 .withColumnRenamed('Grad.Rate','Grad_Rate').withColumnRenamed('Room.Board','Room_Board')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['_c0',\n 'Private',\n 'Apps',\n 'Accept',\n 'Enroll',\n 'Top10perc',\n 'Top25perc',\n 'F_Undergrad',\n 'P_Undergrad',\n 'Outstate',\n 'Room_Board',\n 'Books',\n 'Personal',\n 'PhD',\n 'Terminal',\n 'S_F_Ratio',\n 'perc_alumni',\n 'Expend',\n 'Grad_Rate',\n 'PrivateIndex']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Apps',\n",
    " 'Accept',\n",
    " 'Enroll',\n",
    " 'Top10perc',\n",
    " 'Top25perc',\n",
    " 'F_Undergrad',\n",
    " 'P_Undergrad',\n",
    " 'Outstate',\n",
    " 'Room_Board',\n",
    " 'Books',\n",
    " 'Personal',\n",
    " 'PhD',\n",
    " 'Terminal',\n",
    " 'S_F_Ratio',\n",
    " 'perc_alumni',\n",
    " 'Expend',\n",
    " 'Grad_Rate'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_data = assembler.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "root\n |-- _c0: string (nullable = true)\n |-- Private: string (nullable = true)\n |-- Apps: integer (nullable = true)\n |-- Accept: integer (nullable = true)\n |-- Enroll: integer (nullable = true)\n |-- Top10perc: integer (nullable = true)\n |-- Top25perc: integer (nullable = true)\n |-- F_Undergrad: integer (nullable = true)\n |-- P_Undergrad: integer (nullable = true)\n |-- Outstate: integer (nullable = true)\n |-- Room_Board: integer (nullable = true)\n |-- Books: integer (nullable = true)\n |-- Personal: integer (nullable = true)\n |-- PhD: integer (nullable = true)\n |-- Terminal: integer (nullable = true)\n |-- S_F_Ratio: double (nullable = true)\n |-- perc_alumni: integer (nullable = true)\n |-- Expend: integer (nullable = true)\n |-- Grad_Rate: integer (nullable = true)\n |-- PrivateIndex: double (nullable = false)\n |-- features: vector (nullable = true)\n\n"
    }
   ],
   "source": [
    "assembled_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = assembled_data.select('features','PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+--------------------+------------+\n|            features|PrivateIndex|\n+--------------------+------------+\n|[1660.0,1232.0,72...|         0.0|\n|[2186.0,1924.0,51...|         0.0|\n|[1428.0,1097.0,33...|         0.0|\n|[417.0,349.0,137....|         0.0|\n|[193.0,146.0,55.0...|         0.0|\n|[587.0,479.0,158....|         0.0|\n|[353.0,340.0,103....|         0.0|\n|[1899.0,1720.0,48...|         0.0|\n|[1038.0,839.0,227...|         0.0|\n|[582.0,498.0,172....|         0.0|\n|[1732.0,1425.0,47...|         0.0|\n|[2652.0,1900.0,48...|         0.0|\n|[1179.0,780.0,290...|         0.0|\n|[1267.0,1080.0,38...|         0.0|\n|[494.0,313.0,157....|         0.0|\n|[1420.0,1093.0,22...|         0.0|\n|[4302.0,992.0,418...|         0.0|\n|[1216.0,908.0,423...|         0.0|\n|[1130.0,704.0,322...|         0.0|\n|[3540.0,2001.0,10...|         1.0|\n+--------------------+------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='PrivateIndex',featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='PrivateIndex',featuresCol='features',numTrees=100)\n",
    "gbc = GBTClassifier(labelCol='PrivateIndex',featuresCol='features',maxIter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbc_model = gbc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pred = dtc_model.transform(test_data)\n",
    "rfc_pred = rfc_model.transform(test_data)\n",
    "gbc_pred = gbc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "binary_eval = BinaryClassificationEvaluator(labelCol='PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Decision Tree:\n0.8906419431793537\n"
    }
   ],
   "source": [
    "print(\"Decision Tree:\")\n",
    "print(binary_eval.evaluate(dtc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Random Forest:\n0.9775536759921929\n"
    }
   ],
   "source": [
    "print(\"Random Forest:\")\n",
    "print(binary_eval.evaluate(rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Gradient Boosting Tree:\n0.9617219692040772\n"
    }
   ],
   "source": [
    "print(\"Gradient Boosting Tree:\")\n",
    "print(binary_eval.evaluate(gbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='PrivateIndex',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_acc = acc_eval.evaluate(rfc_pred)\n",
    "dtc_acc = acc_eval.evaluate(dtc_pred)\n",
    "gbc_acc = acc_eval.evaluate(gbc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Here are the results!\n--------------------------------------------------------------------------------\nA single decision tree had an accuracy of: 91.71%\n--------------------------------------------------------------------------------\nA random forest ensemble had an accuracy of: 94.01%\n--------------------------------------------------------------------------------\nA ensemble using GBT had an accuracy of: 90.32%\n"
    }
   ],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*80)\n",
    "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*80)\n",
    "print('A ensemble using GBT had an accuracy of: {0:2.2f}%'.format(gbc_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We can tune hyperparameters of these ML models to get more accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}