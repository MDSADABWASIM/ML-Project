{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda0633cb87348e4e1f83d9c32f4c55bf11",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmean Clustering Project using Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('cluster').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+-----+---------+-----------+------------------+------------------+---------------------+------------------+\n| area|perimeter|compactness|  length_of_kernel|   width_of_kernel|asymmetry_coefficient|  length_of_groove|\n+-----+---------+-----------+------------------+------------------+---------------------+------------------+\n|15.26|    14.84|      0.871|             5.763|             3.312|                2.221|              5.22|\n|14.88|    14.57|     0.8811| 5.553999999999999|             3.333|                1.018|             4.956|\n|14.29|    14.09|      0.905|             5.291|3.3369999999999997|                2.699|             4.825|\n|13.84|    13.94|     0.8955|             5.324|3.3789999999999996|                2.259|             4.805|\n|16.14|    14.99|     0.9034|5.6579999999999995|             3.562|                1.355|             5.175|\n|14.38|    14.21|     0.8951|             5.386|             3.312|   2.4619999999999997|             4.956|\n|14.69|    14.49|     0.8799|             5.563|             3.259|   3.5860000000000003| 5.218999999999999|\n|14.11|     14.1|     0.8911|              5.42|             3.302|                  2.7|               5.0|\n|16.63|    15.46|     0.8747|             6.053|             3.465|                 2.04| 5.877000000000001|\n|16.44|    15.25|      0.888|5.8839999999999995|             3.505|                1.969|5.5329999999999995|\n|15.26|    14.85|     0.8696|5.7139999999999995|             3.242|                4.543|             5.314|\n|14.03|    14.16|     0.8796|             5.438|             3.201|   1.7169999999999999|             5.001|\n|13.89|    14.02|      0.888|             5.439|             3.199|                3.986|             4.738|\n|13.78|    14.06|     0.8759|             5.479|             3.156|                3.136|             4.872|\n|13.74|    14.05|     0.8744|             5.482|             3.114|                2.932|             4.825|\n|14.59|    14.28|     0.8993|             5.351|             3.333|                4.185| 4.781000000000001|\n|13.99|    13.83|     0.9183|             5.119|             3.383|                5.234| 4.781000000000001|\n|15.69|    14.75|     0.9058|             5.527|             3.514|                1.599|             5.046|\n| 14.7|    14.21|     0.9153|             5.205|             3.466|                1.767|             4.649|\n|12.72|    13.57|     0.8686|             5.226|             3.049|                4.102|             4.914|\n+-----+---------+-----------+------------------+------------------+---------------------+------------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "df = spark.read.csv('../datasets/seeds_dataset.csv',inferSchema=True,header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=df.columns,outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "root\n |-- area: double (nullable = true)\n |-- perimeter: double (nullable = true)\n |-- compactness: double (nullable = true)\n |-- length_of_kernel: double (nullable = true)\n |-- width_of_kernel: double (nullable = true)\n |-- asymmetry_coefficient: double (nullable = true)\n |-- length_of_groove: double (nullable = true)\n |-- features: vector (nullable = true)\n\n"
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='features',outputCol='scaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = scaler.fit(final_data).transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "root\n |-- area: double (nullable = true)\n |-- perimeter: double (nullable = true)\n |-- compactness: double (nullable = true)\n |-- length_of_kernel: double (nullable = true)\n |-- width_of_kernel: double (nullable = true)\n |-- asymmetry_coefficient: double (nullable = true)\n |-- length_of_groove: double (nullable = true)\n |-- features: vector (nullable = true)\n |-- scaled_features: vector (nullable = true)\n\n"
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(featuresCol='scaled_features',k=3,seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kmeans.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "429.07559671506715"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WSSSE\n",
    "wssse = model.computeCost(final_data)\n",
    "wssse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[array([ 4.87257659, 10.88120146, 37.27692543, 12.3410157 ,  8.55443412,\n         1.81649011, 10.32998598]),\n array([ 6.31670546, 12.37109759, 37.39491396, 13.91155062,  9.748067  ,\n         2.39849968, 12.2661748 ]),\n array([ 4.06105916, 10.13979506, 35.80536984, 11.82133095,  7.50395937,\n         3.27184732, 10.42126018])]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster centers\n",
    "model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+----------+\n|prediction|\n+----------+\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         1|\n|         1|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         0|\n|         2|\n+----------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "# Result\n",
    "result = model.transform(final_data)\n",
    "result.select('prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We have successfully clustered our data using KMeans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}